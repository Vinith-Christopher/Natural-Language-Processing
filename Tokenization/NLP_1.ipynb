{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be2383c-66a4-47b6-8835-2bf3207a1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44addb98-8ca2-4354-9205-7339b7f7b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'dogs': 2, 'are': 3, 'very': 4, 'loyal': 5, 'to': 6, 'their': 7, 'owners': 8, 'nature': 9, 'is': 10, 'one': 11, 'of': 12, 'most': 13, 'beautiful': 14, 'gift': 15}\n"
     ]
    }
   ],
   "source": [
    "# Example for tokenize the sentences\n",
    "sentences= ['Dogs are very loyal to their owners.', 'Nature is the one of the most beautiful gift']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "# word index from the sentences list\n",
    "word_indexes = tokenizer.word_index\n",
    "print(word_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1225d8e5-6166-4ae4-90c7-fbb5f17c6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 6, 7, 8], [9, 10, 1, 11, 12, 1, 13, 14, 15]]\n"
     ]
    }
   ],
   "source": [
    "# Sequences\n",
    "# create sequences from the sentences\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa02a72-f119-4a9c-960e-8140e8c97d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 9, 10, 4], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "# tokenize new sentences from tokenizer\n",
    "new_sentences = ['Spending time with the nature is very soulful moment', 'Sleeping is the best medicine']\n",
    "new_sentences = tokenizer.texts_to_sequences(new_sentences)\n",
    "print(new_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bee9c40-be54-4ed4-9a53-7fabe8e4d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<oov>': 1, 'the': 2, 'dogs': 3, 'are': 4, 'very': 5, 'loyal': 6, 'to': 7, 'their': 8, 'owners': 9, 'nature': 10, 'is': 11, 'one': 12, 'of': 13, 'most': 14, 'beautiful': 15, 'gift': 16}\n",
      "[[3, 4, 5, 6, 7, 8, 9], [10, 11, 2, 12, 13, 2, 14, 15, 16]]\n"
     ]
    }
   ],
   "source": [
    "# so from above cell we can see that for new words there is no token generated\n",
    "# we need to replace newly encountered words with special values\n",
    "# using oov_token (out of vocabularly token)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100, oov_token = '<oov>' )\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)\n",
    "out_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(out_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cd2128-1e7f-4080-9639-5b0a9ec3f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 2, 10, 11, 5, 1, 1], [1, 11, 2, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Now try with the new sentences\n",
    "# tokenizer.fit_on_texts(new_sentences)\n",
    "# word_index = tokenizer.word_index\n",
    "# print(word_index)\n",
    "new_sentences = ['Spending time with the nature is very soulful moment', 'Sleeping is the best medicine']\n",
    "\n",
    "out_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "print(out_sequences) \n",
    "# 1 means out of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4622549-e957-4a1e-abb0-c263341ea02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Sequences \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c69a587-5cbd-4bff-8c51-1b5bd0ff5376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spending time with the nature is very soulful moment', 'Sleeping is the best medicine']\n",
      "{'<oov>': 1, 'the': 2, 'dogs': 3, 'are': 4, 'very': 5, 'loyal': 6, 'to': 7, 'their': 8, 'owners': 9, 'nature': 10, 'is': 11, 'one': 12, 'of': 13, 'most': 14, 'beautiful': 15, 'gift': 16}\n",
      "[[1, 1, 1, 2, 10, 11, 5, 1, 1], [1, 11, 2, 1, 1]]\n",
      "[[ 1  1  1  2 10 11  5  1  1]\n",
      " [ 0  0  0  0  1 11  2  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "padded_sequences =  pad_sequences(out_sequences)\n",
    "\n",
    "print(new_sentences)\n",
    "print(word_index)\n",
    "print(out_sequences)\n",
    "print(padded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51fe1de-2c83-44d1-ad27-d7f4012ee693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1  2 10 11]\n",
      " [ 1 11  2  1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# customize padded sequences with parameters\n",
    "padded_seqs = pad_sequences(out_sequences,\n",
    "                           padding=\"post\",\n",
    "                           maxlen=6,\n",
    "                           truncating=\"post\")\n",
    "print(padded_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00db7c-a069-44e4-a4ac-55801af6190c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77057f-53f0-49b3-929f-7238ae6f9ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
